From: conte@gatech.edu Subject: TACO submission - TACO-2010-27 Date:
July 6, 2011 12:20:18 PM CDT To: awl8049@cacs.louisiana.edu Cc:
conte@gatech.edu, dbrooks@eecs.harvard.edu

06-Jul-2011

Dear Mr. Lewis,

We have received reviews of your paper, which was submitted for possible
publication in TACO.

According to our Associate Editor David Brooks's recommendation, your
paper has been classified as "Major Revision".  This means that the
paper is being invited to be resubmitted to TACO, but we are requesting
that the major revisions described below are made.  The paper will be
re-reviewed to make sure that the changes adequately address the issues
raised.   If they are adequately addressed, then the paper will be
Accepted.  If they are not adequately addressed, the paper will be
Rejected.  Thus please take care in guaranteeing the resubmitted
manuscript is the best possible.

Once you have revised the paper, you may re-submit it under "Manuscripts
Waiting to be Revised" in the Author Center of Manuscript Central.  Once
again, please follow the format guidelines for TACO submissions.

When you resubmit your paper you must include, as an additional file, a
letter to the editor and reviewers describing how you addressed their
comments below.  In particular, make sure you focus on the key issues
summarized below by the Associate Editor.

As always, you can find information for authors at:

http://www.acm.org/taco/submission.html

If you have any questions please contact me as soon as possible.

Sincerely, Tom Conte Editor-in-Chief of TACO

-------------------------------------------- Here are the Editors'
comments:

The paper must undergo major revisions to be considered further for
publication.  The authors must address all of the comments by the
reviewers, including differentiation from prior work and other
weaknesses pointed out by reviewers.

-------------------------------------------- Here are the reviews:

Referee: 1

Recommendation: Needs Major Revision

Comments: Please see my comments about the related work and about how
the subject matter of power modeling is treated in the paper.

Additional Questions: Review's recommendation for paper type: Full
length technical paper

Should this paper be considered for a best paper award?: No

Does this paper present innovative ideas or material?: No

In what ways does this paper advance the field?: The innovative idea in
this paper is a specific way of using thermal sensors, performance
counters, and bus activity to estimate power consumption. The novelty is
that they show mathematically that server power consumption exhibits
chaotic behavior and develop a way to estimate the power
consumption. IMO, that is a somewhat weak contribution given that server
power modeling is a well trodden area.

Is the information in the paper sound, factual, and accurate?: Yes

If not, please explain why.:

Rate the paper on its contribution to the body of knowledge in
architecture and code optimization (none=1, very important=5): 2

What are the major contributions of the paper?: The paper presents a way
to estimate server power consumption.

Rate how well the ideas are presented (very difficult to understand=1
very easy to understand =5): 3

Rate the overall quality of the writing (very poor=1, excellent=5): 4

Does this paper cite and use appropriate references?: No

If not, what important references are missing?: There is a large body of
literature on modeling power consumption (especially servers) that the
authors have overlooked.

There has been a lot of work on modeling the power and temperature of
the various components considered in this paper [Skadron et al.,
ISCA'03], [Gurumurthi et al., ISCA'05], [Liu et al.,
DAC'08]. [Mesa-Martinez, ASPLOS'10]. The models used by the authors are
much more simplistic those in these prior work.

The authors' claim that there is no work that has looked at the power
profiles of NUMA based architectures is incorrect. See [Ware et al.,
HPCA'10].

There has also been prior work on using statistical methods to model
power consumption [Powell et al., HPCA'09].

Finally, there has been prior work on modeling the power and temperature
of servers [Heath et al., ASPLOS'06].
Should anything be deleted from or condensed in the paper?: No

If so, please explain.:

Is the treatment of the subject complete?: No

If not, What important details / ideas/ analyses are missing?: First,
the authors have to address how their work is related to the papers I
have listed. Since power modeling of servers is a well-trodden area, the
authors have to highlight how their contribution advances the state of
the art/knowledge.

Second, related to the above point, since the per component models are
not new, the novelty has to be in the way the power modeling itself is
done and the additional benefits and insights such a modeling approach
will provide. While the idea of a Chaotic Attractor Predictor appears to
be novel, none of the quantitative results are convincing that such a
predictor is an improvement over the prior approaches. The authors
either need to quantitatively compare, or atleast provide a strong
qualitative discussion about how the CAP predictor advances the
state-of-the-knowledge on power modeling.


Referee: 2

Recommendation: Needs Minor Revision

Comments: I'd like the authors to discuss the time interval used in the
evaluation (for the collection of the PeC and measurement of
power).  This is also needed in the appendix which has equations for
energy, without discussing the time interval to which the equations
apply.  The time interval determines the possible applications (power
capping) for using the power estimation.  For example, actuators that
use the parameters must work on the same time scale to be effective.

I could not follow the discussion on calibrating the CAP. The text
claims that p=100 and 4 workloads were run to calibrate the model. I
take this to mean that the 4 workloads together were divided into 100
time intervals (of many seconds or minutes?) and the PeC values and
measured power were averaged over each interval to calibrate the
model.  Is this correct?  It would be helpful to add a couple of
sentences to be clear how you obtain the 100 vectors required for
calibration.

The definition of E_em is very strange. E_em is defined as a component
of server power, but the equation seems to contain the entire servers
power in the form of V(t) * I(t), which contains CPU power (and other
components) which have been already accounted for.   In fact, the fan
power itself should be part of V(t) * I(t), the DC power, so it is not
clear why they are added together in the equation for P_elect.Please define SMPS.

I was confused by Section 3.6 which claims that power is controlled, but
the rest of the paper does not come back to how power is controlled or
how controlling power is relevant for developing the model.

I'd like a longer discussion of the step-wise process in section 5 for
predicting the distant future.  I thought that the function f^ was for
estimating the power of the system for interval k, based on PeC
measurements made during time interval k.  How does one use this to get
power estimates for which PeC has not yet been measured?  Are the values
for PeC also being predicted?

I found the equation for E_intel_proc (in the appendix) surprising
because the coefficients for the temperature of each core is so
different (more than a factor of 70x).  It looks like core 1 does not
contribute much to the power of the processor, which is hard to
believe.   I would expect them to be more balanced as in the AMD
processor. If all the workload were scheduled on core 1 (core 0
disabled), would these equations still hold?

Additional Questions: Review's recommendation for paper type: Full
length technical paper

Should this paper be considered for a best paper award?: No

Does this paper present innovative ideas or material?: Yes

In what ways does this paper advance the field?: Prior methods of
estimating system power have been based on linear, auto-regressive
modeling. The authors propose to model the system as a chaotic process
and report reduced power estimate errors (around 1%) as compared the the
prior approaches (2-3%).  I am not aware of this type of model being
used before for system power estimation.

Is the information in the paper sound, factual, and accurate?: Yes

If not, please explain why.:

Rate the paper on its contribution to the body of knowledge in
architecture and code optimization (none=1, very important=5): 3

What are the major contributions of the paper?: The major contribution
is to provide a method for estimating power consumption that is more
accurate (by about a factor of 2) than other known methods. I only rate
this a 3 because it is not clear how it will be applied in practical
applications, given that measuring power directly is becoming cheaper
and commonplace in the types of servers studied here.

Rate how well the ideas are presented (very difficult to understand=1
very easy to understand =5): 2

Rate the overall quality of the writing (very poor=1, excellent=5): 3

Does this paper cite and use appropriate references?: Yes

If not, what important references are missing?:

Should anything be deleted from or condensed in the paper?: No

If so, please explain.:

Is the treatment of the subject complete?: No

If not, What important details / ideas/ analyses are missing?: The
authors should address the time scale at which the energy estimation can
be done. (What is the time interval used in the experiments for
collection of performance counters and power measurements?)  This
determines the applications which can use these estimations.


Referee: 3

Recommendation: Needs Major Revision

Comments: This paper presents some interesting observations about system
power behavior and how its "chaotic" nature can be better modeled with
the CAP approach. However, while I feel there is potential value in this
approach, I am somewhat uncertain about the main premise of this
work. The initial discussions of the paper describe power modeling for
NUMA systems, individual subsystem-level power models, inadequacy of
linear regression models for power estimation, thermal effects, and the
chaotic power behavior, while the evaluations do not explicitly revisit
and elaborate on these. Below are my main comments related to these and
some additional technical issues:

- First, I feel the title of this work is somewhat vague. What does
  "time-series approximation of energy consumption estimation" mean? Do
  you fit an estimated energy consumption to a timeseries to predict
  future power behavior? Are you proposing CAP as a timeseries method
  for estimated power, or are you proposing an instantaneous energy
  estimation method based on performance counters; or both? This is not
  clearly explained in the paper. Second, what is "based on server
  workload"? It seems the evaluations are only for Spec CPU benchmarks.

- What do you specifically propose for NUMA that prior work omits? How
  do you evaluate the improvements compared to a non-NUMA model?
- I am also not sure whether the complexity of CAP is commonly necessary
  for system power estimation. Several prior system-level power
  estimation methods show very good accuracy with very simple models,
  such as utilization-based estimations. Why do they not work well in
  this scenario?

- You highlight that your approach accounts for thermal effects in power
  estimation. Does this only pertain to processor power estimation, or
  for overall system?

- The introduction mentions that prior work "assumes a linear
relationship between dependent variables and previous data points". Do
you mean (i) they predict future system behavior based on a linear
model; or (ii) they use a linear combination of system measurements to
predict instantaneous power?  For (i) there are some prior studies that
use statistical or pattern based models to predict future system
power/performance behavior, as it is commonly known that
dynamically-varying workload behavior impacts system behavior, which
does not necessarily vary in a linear way.

- Pproc: (1) The derived processor power model (intel) shows a ~100X
  difference in sensitivity to two thermal sensors. Is there any reason
  for this discrepancy? (2) The model seems quite oblivious to workload
  and very dependent on temperature. Considering temperature does not
  vary instantaneously, while power does, does this model remain valid
  for different workload intensities? For example an idle period after a
  long running cpu burn can result in a higher estimated power then a
  long-running idle period. Or the order of different workload
  intensities can impact the estimated power.

- Ehdd & Eboard: I think the HDD power would also depend random
  vs. sequential writes and the involvement of disk cache. For the
  board, I expected more or less constant power, do you see any
  significant variations from different workloads?

- As I have mentioned previously, it is also quite hard to gauge the
  accuracy of the subsystem models without any validation, and
  particularly for some of the components Spec CPU would be limiting as
  it is designed not to exercise components below memory.

- The observations on the chaotic nature of power bahavior are quite
  interesting. Are the two conditions with Lyapunov and Hurst parameter
  sufficient to consider power behavior chaotic? Can you provide some
  intuition behind these? I cannot see how the two requisites (high
  sensitivity to initial condition & dense period orbits) hold
  necessarily true for power behavior?

- Power measurements: The measured power for both systems vary between
  60-70W from idle-active. This seems rather low for both servers, and
  the delta seems very low for the entire system including CPUs, memory,
  and so on. Could you please provide more details on the system
  configurations and what is reported.

- Please consider reviewing the paper for language. Here are a few typos
that caught my eye:  - valid valid --> validate  - CAT --> CAP  - 5.2:
number of past observations --> number of future observations

Additional Questions: Review's recommendation for paper type: Full
length technical paper

Should this paper be considered for a best paper award?: No

Does this paper present innovative ideas or material?: Yes

In what ways does this paper advance the field?: This paper argues that
existing power estimation models based on linear regression methods do
not capture the nonlinear nature of workloads and thus system power
characteristics. The authors propose a new chaotic attractor prediction
model and demonstrate that this model more accurately captures dynamic
power behavior.

Is the information in the paper sound, factual, and accurate?: Yes

If not, please explain why.:

Rate the paper on its contribution to the body of knowledge in
architecture and code optimization (none=1, very important=5): 3

What are the major contributions of the paper?: + System level power
model based on hardware and OS-level performance counters + Power models
for different subsystems + Validation with real system experiments

Rate how well the ideas are presented (very difficult to understand=1
very easy to understand =5): 3

Rate the overall quality of the writing (very poor=1, excellent=5): 3

Does this paper cite and use appropriate references?: Yes

If not, what important references are missing?:

Should anything be deleted from or condensed in the paper?: Yes

If so, please explain.: Majority of the paper is devoted to introducing
the power model, susbsystem models, CAP, and a variety of other issues
such as timeseries forecasting, linearity issues, DC vs. AC power
distribution and alternative performance counters for improving power
estimation. After these a few examples of estimated and total power is
shown for some SPEC CPU benchmarks, which do not help us (i) validate
any of the assumptions for subsystem models; and (ii) build any
intuition to how the CAP better understands and predicts power behavior.

I recommend reducing some of the lengthy discussions at the beginning of
this work and removing some tangential points (i.e., AC vs. DC,
additional counters). It would be much more useful to use the remaining
space to expand on the observed results and to provide some insights to
why the CAP method is a better model for system power estimation.

Is the treatment of the subject complete?: No

If not, What important details / ideas/ analyses are missing?: (Please
see my previous comments about condensing the initial discussions in the
paper above)
